import fs from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

console.log('ğŸ”§ æ›´æ–°æ™ºèƒ½çˆ¬è™«é…ç½®...');

// è¯»å–çˆ¬è™«é…ç½®
const configPath = path.join(__dirname, 'crawler-config.json');
if (!fs.existsSync(configPath)) {
  console.log('âŒ è¯·å…ˆè¿è¡Œ prepare-crawler-config.js ç”Ÿæˆé…ç½®æ–‡ä»¶');
  process.exit(1);
}

const crawlerConfig = JSON.parse(fs.readFileSync(configPath, 'utf8'));

// è¯»å–æ™ºèƒ½çˆ¬è™«æ–‡ä»¶
const crawlerPath = path.join(__dirname, 'intelligent-game-crawler.js');
let crawlerContent = fs.readFileSync(crawlerPath, 'utf8');

// æ›´æ–° GAMES_CONFIG
const configString = JSON.stringify(crawlerConfig, null, 2);
const updatedContent = crawlerContent.replace(
  /const GAMES_CONFIG = \{[^}]*\};/s,
  `const GAMES_CONFIG = ${configString};`
);

// ä¿å­˜æ›´æ–°åçš„æ–‡ä»¶
fs.writeFileSync(crawlerPath, updatedContent);

console.log(`âœ… æ™ºèƒ½çˆ¬è™«é…ç½®å·²æ›´æ–°`);
console.log(`ğŸ¯ é…ç½®äº† ${Object.keys(crawlerConfig).length} ä¸ªæ¸¸æˆå¾…çˆ¬å–`);

// æ˜¾ç¤ºå‰10ä¸ªæ¸¸æˆ
console.log('\nğŸ® å‰10ä¸ªå¾…çˆ¬å–æ¸¸æˆ:');
Object.entries(crawlerConfig).slice(0, 10).forEach(([id, config], index) => {
  console.log(`${index + 1}. ${config.name} (${config.source})`);
});

console.log('\nğŸš€ ç°åœ¨å¯ä»¥è¿è¡Œçˆ¬è™«äº†:');
console.log('npm run crawl-games');
console.log('æˆ–è€…');
console.log('node scripts/run-crawler.js'); 